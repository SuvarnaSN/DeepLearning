{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4ec036-8be0-4b51-b3f3-af4423191090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Suvarna\\AppData\\Local\\Temp\\ipykernel_17304\\2636927568.py:12: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n",
      "  tar.extractall()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "X_train shape: (10000, 3072)\n",
      "y_train shape: (10000, 10)\n",
      "Epoch 0, Loss: 2.519491\n",
      "Epoch 10, Loss: 2.276183\n",
      "Epoch 20, Loss: 2.240506\n",
      "Epoch 30, Loss: 2.212592\n",
      "Epoch 40, Loss: 2.188195\n",
      "Epoch 50, Loss: 2.166771\n",
      "Epoch 60, Loss: 2.148190\n",
      "Epoch 70, Loss: 2.131369\n",
      "Epoch 80, Loss: 2.115679\n",
      "Epoch 90, Loss: 2.100763\n"
     ]
    }
   ],
   "source": [
    "import numpy as npy\n",
    "import pickle\n",
    "import urllib.request\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "def loadCifarDataset():\n",
    "    cifarTar_urlLink = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    if not os.path.exists(\"cifar-10-python.tar.gz\"):\n",
    "        urllib.request.urlretrieve(cifarTar_urlLink, \"cifar-10-python.tar.gz\")\n",
    "    with tarfile.open(\"cifar-10-python.tar.gz\", \"r:gz\") as tar:\n",
    "        tar.extractall()\n",
    "\n",
    "def cifarBatchLoadandDataExtract(inputfile):\n",
    "    with open(inputfile, 'rb') as ifile:\n",
    "        Dictdata = pickle.load(ifile, encoding='bytes')\n",
    "        Cifarimages = Dictdata[b'data'] / 255.0\n",
    "        Cifarlabels = npy.array(Dictdata[b'labels'])\n",
    "        Cifarlabels = npy.eye(10)[Cifarlabels.reshape(-1)]\n",
    "    return Cifarimages, Cifarlabels\n",
    "\n",
    "def initialize_parameters(input_size=3072, hidden_size=128, output_size=10):\n",
    "    npy.random.seed(42)\n",
    "    weightLayer1 = npy.random.randn(input_size, hidden_size) * npy.sqrt(2.0 / input_size)\n",
    "    biasValue1 = npy.zeros((1, hidden_size))\n",
    "    weightLayer2 = npy.random.randn(hidden_size, output_size) * npy.sqrt(2.0 / hidden_size)\n",
    "    biasValue2 = npy.zeros((1, output_size))\n",
    "    return weightLayer1, biasValue1, weightLayer2, biasValue2\n",
    "\n",
    "def reluActivationFunction(Zout):\n",
    "    return npy.maximum(0, Zout)\n",
    "\n",
    "def softmaxFunction(Zout):\n",
    "    exp_Z = npy.exp(Zout - npy.max(Zout, axis=1, keepdims=True))\n",
    "    return exp_Z / npy.sum(exp_Z, axis=1, keepdims=True)\n",
    "\n",
    "def forwardPropagationFunction(Xtrainset, weightLayer1, biasValue1, weightLayer2, biasValue2):\n",
    "    Z1out = npy.dot(Xtrainset, weightLayer1) + biasValue1\n",
    "    A1actout = reluActivationFunction(Z1out)\n",
    "    Z2out = npy.dot(A1actout, weightLayer2) + biasValue2\n",
    "    A2actout = softmaxFunction(Z2out)\n",
    "    return Z1out, A1actout, Z2out, A2actout\n",
    "\n",
    "def returnReluDerivative(Zout):\n",
    "    return (Zout > 0).astype(float)\n",
    "\n",
    "def computeLossFunction(A2out, Yset, weightLayer1, weightLayer2, lambda_=0.01):\n",
    "    mtraining = Yset.shape[0]\n",
    "    crossEntropyVal = -npy.sum(Yset * npy.log(A2out + 1e-8)) / mtraining\n",
    "    L2regVal = (lambda_ / (2 * mtraining)) * (npy.sum(weightLayer1**2) + npy.sum(weightLayer2**2))\n",
    "    return crossEntropyVal + L2regVal\n",
    "\n",
    "def backwardPropagationFunction(Xtrainset, Yset, weightLayer1, biasValue1, weightLayer2, biasValue2, Z1out, A1actout, A2actout, lambda_=0.01):\n",
    "    mtraining = Xtrainset.shape[0]\n",
    "    outputGradient_dZ2 = A2actout - Yset\n",
    "    predict_dW2 = (npy.dot(A1actout.T, outputGradient_dZ2) / mtraining) + (lambda_ * weightLayer2 / mtraining)\n",
    "    bias_db2 = npy.sum(outputGradient_dZ2, axis=0, keepdims=True) / mtraining\n",
    "    outputGradient_dZ1 = npy.dot(outputGradient_dZ2, weightLayer2.T) * returnReluDerivative(Z1out)\n",
    "    predict_dW1 = (npy.dot(Xtrainset.T, outputGradient_dZ1) / mtraining) + (lambda_ * weightLayer1 / mtraining)\n",
    "    bias_db1 = npy.sum(outputGradient_dZ1, axis=0, keepdims=True) / mtraining\n",
    "    return predict_dW1, bias_db1, predict_dW2, bias_db2\n",
    "\n",
    "def update_Dataparameters(weightLayer1, biasValue1, weightLayer2, biasValue2, predict_dW1, bias_db1, predict_dW2, bias_db2, learningRateval=0.005):\n",
    "    weightLayer1 -= learningRateval * predict_dW1\n",
    "    biasValue1 -= learningRateval * bias_db1\n",
    "    weightLayer2 -= learningRateval * predict_dW2\n",
    "    biasValue2 -= learningRateval * bias_db2\n",
    "    return weightLayer1, biasValue1, weightLayer2, biasValue2\n",
    "\n",
    "def trainWeightsandBias(Xtrainset, Ytrainset, noofEpochs=500, learningRateval=0.005, lambda_=0.01):\n",
    "    weightLayer1, biasValue1, weightLayer2, biasValue2 = initialize_parameters()\n",
    "    for epoch in range(noofEpochs):\n",
    "        Z1out, A1actout, Z2out, A2actout = forwardPropagationFunction(Xtrainset, weightLayer1, biasValue1, weightLayer2, biasValue2)\n",
    "        lossValue = computeLossFunction(A2actout, Ytrainset, weightLayer1, weightLayer2, lambda_)\n",
    "        predict_dW1, bias_db1, predict_dW2, bias_db2 = backwardPropagationFunction(Xtrainset, Ytrainset, weightLayer1, biasValue1, weightLayer2, biasValue2, Z1out, A1actout, A2actout, lambda_)\n",
    "        weightLayer1, biasValue1, weightLayer2, biasValue2 = update_Dataparameters(weightLayer1, biasValue1, weightLayer2, biasValue2, predict_dW1, bias_db1, predict_dW2, bias_db2, learningRateval)\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {lossValue:.6f}\")\n",
    "    return weightLayer1, biasValue1, weightLayer2, biasValue2\n",
    "\n",
    "def predictFunction(Xtestset, weightLayer1, biasValue1, weightLayer2, biasValue2):\n",
    "    _, _, _, A2actout = forwardPropagationFunction(Xtestset, weightLayer1, biasValue1, weightLayer2, biasValue2)\n",
    "    predictionsValue = npy.argmax(A2actout, axis=1)\n",
    "    return predictionsValue\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    loadCifarDataset()\n",
    "    Xtrainset, ytrainset = cifarBatchLoadandDataExtract(\"cifar-10-batches-py/data_batch_1\")\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    print(\"X_train shape:\", Xtrainset.shape)\n",
    "    print(\"y_train shape:\", ytrainset.shape)\n",
    "    weightLayer1, biasValue1, weightLayer2, biasValue2 = trainWeightsandBias(Xtrainset, ytrainset, noofEpochs=500, learningRateval=0.005, lambda_=0.01)\n",
    "    predictionsValue = predictFunction(Xtrainset, weightLayer1, biasValue1, weightLayer2, biasValue2)\n",
    "    labelsActualValue = npy.argmax(ytrainset, axis=1)\n",
    "    accuracyPercentage = npy.mean(predictionsValue == labelsActualValue) * 100\n",
    "    print(f\"Training Accuracy: {accuracyPercentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a9edbd-b24b-4d6c-aa74-541353e9c886",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
